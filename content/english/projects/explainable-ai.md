---

title: "Explainable AI"
image: "https://images.unsplash.com/photo-1616161560417-66d4db5892ec?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1170&q=80"
draft: false
---

-- Interpreting black box state of the art Deep Neural Networks

-- Understanding robustness of Deep Neural Networks to Adversarial attacks

-- Human in the Loop approach to ML to achieve better explainability

The recent tremendous success in ML/AI is attributed to the advent of deep learning algorithms. While these algorithms have performed extremely well in NLP, Vision, Speech and other domains, deploying them in several applications is often not a comfortable decision for industries. The fundamental reason for this is that deep neural models trade-off explainability with accuracy. The goal of the project is to contribute to the growing literature on explainable machine learning algorithms.